{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoFgN5gQm8lL"
      },
      "outputs": [],
      "source": [
        "!pip install azure-identity\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install azure-search-documents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import QueryType"
      ],
      "metadata": {
        "id": "5qQghipurf7F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip3 install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "\n",
        "# If your enviornment variable giving you previous values,\n",
        "# then delete existing one And know set new one\n",
        "# del os.environ['AZURE_SEARCH_SERVICE']\n",
        "\n",
        "# Replace these with your own values, either in environment variables or directly here\n",
        "AZURE_STORAGE_ACCOUNT = os.environ.get(\"AZURE_STORAGE_ACCOUNT\")  # This is only in use if you want to store your data in azure blob storage\n",
        "AZURE_STORAGE_CONTAINER = os.environ.get(\"AZURE_STORAGE_CONTAINER\")\n",
        "\n",
        "AZURE_SEARCH_SERVICE = os.environ.get(\"AZURE_SEARCH_SERVICE\")\n",
        "AZURE_SEARCH_INDEX = os.environ.get(\"AZURE_SEARCH_INDEX\")\n",
        "AZURE_SEARCH_KEY = os.environ.get(\"AZURE_SEARCH_KEY\")\n",
        "\n",
        "AZURE_OPENAI_SERVICE = os.environ.get(\"AZURE_OPENAI_SERVICE\")\n",
        "AZURE_OPENAI_GPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_GPT_DEPLOYMENT\")\n",
        "AZURE_OPENAI_CHATGPT_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_CHATGPT_DEPLOYMENT\")\n",
        "AZURE_OPENAI_CHATGPT_MODEL = os.environ.get(\"AZURE_OPENAI_CHATGPT_MODEL\")\n",
        "\n",
        "OPENAI_API_KEY= os.environ.get(\"OPENAI_API_KEY\")\n",
        "# AZURE_TENANT_ID = os.environ.get(\"AZURE_TENANT_ID\")\n",
        "# AZURE_CLIENT_SECRET = os.environ.get[\"AZURE_CLIENT_SECRET\"]\n",
        "# AZURE_CLIENT_ID = os.environ.get[\"AZURE_CLIENT_ID\"]\n",
        "\n",
        "KB_FIELDS_CONTENT = os.environ.get(\"KB_FIELDS_CONTENT\")\n",
        "KB_FIELDS_CATEGORY = os.environ.get(\"KB_FIELDS_CATEGORY\")\n",
        "KB_FIELDS_SOURCEPAGE = os.environ.get(\"KB_FIELDS_SOURCEPAGE\")\n"
      ],
      "metadata": {
        "id": "BJdpzfZxsIIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the current user identity to authenticate with Azure OpenAI, Cognitive Search and Blob Storage (no secrets needed,\n",
        "# just use 'az login' locally, and managed identity when deployed on Azure). If you need to use keys, use separate AzureKeyCredential instances with the\n",
        "# keys for each service\n",
        "azure_credential = DefaultAzureCredential()\n",
        "\n",
        "\n",
        "# Used by the OpenAI SDK\n",
        "openai.api_type = \"azure\"\n",
        "openai.api_base = f\"https://{AZURE_OPENAI_SERVICE}.openai.azure.com\"\n",
        "openai.api_version = \"2023-05-15\"\n",
        "\n",
        "\n",
        "# Comment these two lines out if using keys, set your API key in the OPENAI_API_KEY environment variable instead\n",
        "# openai.api_type = \"azure_ad\"\n",
        "# openai.api_key = azure_credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
        "openai.api_key=OPENAI_API_KEY\n",
        "\n",
        "# Set up clients for Cognitive Search and Storage\n",
        "search_client = SearchClient(\n",
        "    endpoint=f\"https://{AZURE_SEARCH_SERVICE}.search.windows.net\",\n",
        "    index_name=AZURE_SEARCH_INDEX,\n",
        "    credential=AZURE_SEARCH_KEY)\n"
      ],
      "metadata": {
        "id": "CmwQNLeUs0St"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chat roles\n",
        "SYSTEM = \"system\"\n",
        "USER = \"user\"\n",
        "ASSISTANT = \"assistant\"\n",
        "\n",
        "# previous chat\n",
        "system_message_chat_conversation = \"\"\"Assistant helps the company employees with their healthcare plan questions, and questions about the employee handbook. Be brief in your answers.\n",
        "Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\n",
        "Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. Use square brackets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
        "\"\"\"\n",
        "chat_conversations = [{\"role\" : SYSTEM, \"content\" : system_message_chat_conversation}]\n",
        "\n",
        "summary_prompt_template = \"\"\"Below is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question. Source names are not good search terms to include in the search query.\n",
        "\n",
        "Summary:\n",
        "{summary}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Search query:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9Ax3wEhos5lv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute this cell multiple times updating user_input to accumulate chat history\n",
        "user_input = \"Does my plan cover annual eye exams? Any type\"\n",
        "\n",
        "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
        "exclude_category = None\n",
        "\n",
        "# To check if there is any chat history available\n",
        "if len(chat_conversations) > 1:\n",
        "    # If there is previous chat then provide the summary\n",
        "    query_completion = openai.Completion.create(\n",
        "        engine=AZURE_OPENAI_GPT_DEPLOYMENT,\n",
        "        prompt=summary_prompt_template.format(summary=str(chat_conversations), question=user_input),\n",
        "        temperature=0.7,\n",
        "        max_tokens=32,\n",
        "        stop=[\"\\n\"])\n",
        "    search = query_completion.choices[0].text\n",
        "else:\n",
        "  # set the user input to search if there is no chat history\n",
        "    search = user_input\n"
      ],
      "metadata": {
        "id": "mxdQ-xUps9TX"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively simply use search_client.search(q, top=3) if not using semantic search\n",
        "print(\"Searching:\", search)\n",
        "print(\"-------------------\")\n",
        "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
        "r = search_client.search(search,\n",
        "                         filter=filter,\n",
        "                        #  query_type=QueryType.SEMANTIC,\n",
        "                         query_language=\"en-us\",\n",
        "                         query_speller=\"lexicon\",\n",
        "                         semantic_configuration_name=\"default\",\n",
        "                         top=3)\n",
        "\n"
      ],
      "metadata": {
        "id": "3gTqsItD6jrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming KB_FIELDS_SOURCEPAGE and KB_FIELDS_CONTENT are the actual field names you're using\n",
        "results = []\n",
        "\n",
        "for doc in r:\n",
        "    source_page = doc.get(KB_FIELDS_SOURCEPAGE, \"\")\n",
        "    content = doc.get(KB_FIELDS_CONTENT, \"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\")\n",
        "    result = f\"{source_page}: {content}\"\n",
        "    results.append(result)\n",
        "\n",
        "content = \"\\n\".join(results)\n",
        "user_content = user_input + \" \\nSOURCES:\\n\" + content\n",
        "print(user_content)  # Print the user_content, not 'result'"
      ],
      "metadata": {
        "id": "q1xwqXgRZ6S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_content = user_input + \" \\nSOURCES:\\n\" + content\n",
        "\n",
        "chat_conversations.append({\"role\": USER, \"content\": user_content })\n",
        "\n",
        "chat_completion = openai.ChatCompletion.create(\n",
        "    deployment_id=AZURE_OPENAI_CHATGPT_DEPLOYMENT,\n",
        "    model=AZURE_OPENAI_CHATGPT_MODEL,\n",
        "    messages=chat_conversations,\n",
        "    temperature=0.7,\n",
        "    max_tokens=1024,\n",
        "    n=1)\n",
        "chat_content = chat_completion.choices[0].message.content\n",
        "'''\n",
        "reset user content to avoid sources in conversation history\n",
        "add source as a single shot in query conversation\n",
        "'''\n",
        "chat_conversations[-1][\"content\"] = user_input\n",
        "chat_conversations.append({\"role\":ASSISTANT, \"content\": chat_content})\n",
        "\n",
        "print(\"\\n-------------------\\n\")\n",
        "[print(conversation) for conversation in chat_conversations]"
      ],
      "metadata": {
        "id": "fbLse1uOXr--",
        "outputId": "8f81d48f-7468-44c5-9343-7f2990197147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------------------\n",
            "\n",
            "{'role': 'system', 'content': \"Assistant helps the company employees with their healthcare plan questions, and questions about the employee handbook. Be brief in your answers.\\nAnswer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question.\\nEach source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. Use square brackets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\\n\"}\n",
            "{'role': 'user', 'content': 'Does my plan cover annual eye exams? \\nSOURCES:\\n'}\n",
            "{'role': 'user', 'content': 'Does my plan cover annual eye exams?'}\n",
            "{'role': 'assistant', 'content': \"I'm sorry, I need more information. Can you please tell me what type of healthcare plan you have?\"}\n",
            "{'role': 'user', 'content': 'Does my plan cover annual eye exams? Any type'}\n",
            "{'role': 'assistant', 'content': 'Yes, your healthcare plan covers annual eye exams. [info1.txt]'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    }
  ]
}